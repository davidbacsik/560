---
title: 'Problem Set #3'
output:
  html_document:
    df_print: paged
---
```{r}
library(ggplot2)
```

# 560
# Problem Set ##

## Due Date: Thursday, May 10
### David Bacsik

### Problem 1
In homework 2, you were investigating the de novo mutation rate of R. Waterstonii.
In a given generation, you observed the following mutation counts in 12 different
isolates:

```{r}
mutations = c(12,15,10,4,6,15,18,12,7,11,5,14)

mutation_data = data.frame(mutations)

mutation_data

```

#### 1a
**Obtain 1,000 bootstrap samples from your data and recompute λ' for these bootstrap examples.**

I will use the boot package to randomly resample this data 1000 times. Each time, I will compute lambda as the mean of the sample. The resulting distribtuion is:
```{r}
library(boot)

set.seed(1)

samplemean = function(x, d) {
  return(mean(x[d]))
}

lambda_ests = boot(data = mutation_data$mutations, statistic = samplemean, R = 1000)

lambda_ests.vals = data.frame(t = lambda_ests$t[1:1000])

ggplot(lambda_ests.vals, aes(x=t)) + geom_histogram() +
   labs(title="Lambda estimate", subtitle='1000 bootstrap samplings', y="count", x = "lambda")
```

#### 1b
**Compute the variance of λ'.**

```{r}
var(lambda_ests$t[1:1000])
```

#### 1c
**Generate a 95% confidence interval for λ' using the normal approximation method.**
The lambda estimates should be approximatley normally distributed, because they are a stastic calculated over many random samples.

The edges of the 95% confidence interval of the normal approximation of this distribution are:

```{r}
m = mean(lambda_ests$t[1:1000])
v = var(lambda_ests$t[1:1000])

qnorm(0.025, mean = m, sd = sqrt(v))
qnorm((1-0.025), mean = m, sd = sqrt(v))
```

#### 1d QUESTION
**Generate a 95% confidence interval for λ' using the percentile method.**

I want to find the values that lie, within our statistic distribution, at the edge of the 95% confidence interval.

Does this make use of the sign test, as is outlined in lecture 7? Or is it simply the 25th (0.025%) and 975th (97.5%) term in the ordered list of the lambda estimates? This second value is much closer to the normal distribution, which is what I would expect for a resampling that is sufficiently large.

```{r}
lambda_ests.sorted = sort(lambda_ests$t[1:1000])

pbinom(468, 1000, prob=0.5)

lambda_ests.sorted[468]
lambda_ests.sorted[(1000-468+1)]

lambda_ests.sorted[25]
lambda_ests.sorted[(1000-25+1)]

```

#### 1e QUESTION
**Compare the results from c and d. Which do you prefer, and why?**

In this case, I prefer the percentile approach. While the values are similar between the normal approximation and percentile approach, since the percential approach was computationally trivial, I prefer to use values that are present in the bootstrap set to describe the bootstrap set, rather than the inferred values of the normal distribution.

### 2
You are studying the effect of a new enzyme on the number of PCR cycles required for a reaction. You split each of your 16 samples into two and perform the reactions with the old and new enzymes. The following table summarizes your data on the number of cycles required for each pair of reactions using the old and new enzymes:

```{r}
old = c(7,5,7,7,10,12,5,13,11,9,9,8,8,13,6,10)
new = c(6,8,8,2,9,9,7,7,4,7,8,7,7,11,8,6)

enzyme_data = data.frame(old, new)

enzyme_data
```

### Approach A: Paired T-Test
#### 2A - a
**Briefly describe (in words) your strategy. Why did you choose this approach?**

These data are paired. Each observation is from a single sample tested with two different conditions (old vs new enzyme). I will use a paired t-test to evaluate whether the conditions affect the observations.

#### 2A - b
**What are the null and alterative hypotheses for this test**

The null hypothesis for this test is that the mean difference between pairs is 0. The alternative hypothesis is that the mean difference between pairs is not 0.

#### 2A - c
**What assumptions does your approach make? Are they all satisfied? How do you know?**

*The data are continuous; this is true, assuming we know our measurment technique allows continous observations.
*Each (paired) observation is independent; this is also true, assuming we know our sampling method is not biased.
*The data are approximately normally distributed; by eye, this is true for the 'new' data, and it is unclear whether it is true for the 'old' data. 

```{r}
old_plot = ggplot(enzyme_data, aes(x=old)) + geom_bar()
new_plot = ggplot(enzyme_data, aes(x=new)) + geom_bar()

old_plot
new_plot
```

#### 2A - d
**What is the p-value from your analysis?**

```{r}
paired_enzyme_test = t.test(enzyme_data$old, enzyme_data$new, paired = TRUE)

paired_enzyme_test$p.value
```

#### 2A - e
**What do you conclude (be precise about the conclusion)?**

Because the p value is less than 0.05, I conclude that the mean of differences between the pairs is not 0. Because our experimental design only changed the enzyme in the reaction, we can infer causality. I infer that changing the enzyme produced a difference in the number of cycles required for each pair of reactions. Because this was a two-sided test, I cannot conclude the direction or magnitude of the difference, only that a difference is present.

### Approach B: Wilcoxan Signed Rank Test
#### 2B - a
**Briefly describe (in words) your strategy. Why did you choose this approach?**
These data are paired. Each observation is from a single sample tested with two different conditions (old vs new enzyme). In the previous approach, paired t-test, I found that the data are not clearly normally distributed. Now, I will use a non-parametric test, the Wilcoxon Signed Rank Test, which does not require normally distributed data to be valid.

#### 2B - b
**What are the null and alterative hypotheses for this test**
The null hypothesis is that the populations the two samples are drawn from have the same median. The alternative hypothesis is that they are drawn from populations with different medians.

#### 2B - c
**What assumptions does your approach make? Are they all satisfied? How do you know?**

*The data are continuous; this is true, assuming we know our measurment technique allows continous observations.
*Each (paired) observation is independent; this is also true, assuming we know our sampling method is not biased.
*The data have a symmmetric distribution; this is true for both 'old' and 'new' data sets.

#### 2B - d
**What is the p-value from your analysis?**

```{r}
paired_enzyme_wilcoxtest = wilcox.test(enzyme_data$old, enzyme_data$new, paired = TRUE)

paired_enzyme_wilcoxtest$p.value
```

#### 2B - e
**What do you conclude (be precise about the conclusion)?**
The p-value given for the non-parametric test is 0.06, which is above the common threshold of 0.05. This test is less powerful than the t-test. However, this tests assumptions were met, while it is not clear that the t-test's assumptions were met.

Given this value, I would think it is likely that the medians of the populations the old and new data are drawn from are different; because we know the experimental design, we can say that the median number of cycles needed to complete the reaction with the new enzyme is likely different from the median number needed to complete the reaction with the old enzyme. However, I would not be very confident in this conclusion.

### 3
#### 3a QUESTION
**After your yearly checkup, the doctor has bad news and good news. The bad news is that you tested positive for a serious disease, and that the test is 99% accurate (i.e. the probability of testing positive given that you have the disease is 0.99, as is the probability of testing negative given that you don’t have the disease). The good news is that this is a rare disease, striking only 1 in 10,000 people. Why is it good news that the disease is rare? What are the chances that you actually have the disease?**

Given that you tested positive, the chance that you actually have the disease depends on the accuracy of the test (a more specific test increases the chance that you have the disease) and the chance that you have the disease in the absence of testing (the background rate of the disease). Since the background rate is very low, even though you tested positive on the test, it is still overwhelmingly likely that you DO NOT have the disease:

A = you have the disease  
B = you tested positive

\begin{equation*}
P(A|B) = \frac{P(B|A)P(A)}{P(B)}
\end{equation*}

In the absence of testing, P(A) is = 1/10,000.  
Since the test is 99% sensitive, P(B|A) is 0.99.  
Since the test is 99% specific, and the disease is very rare, P(B) (in the absence of a condition) is about 0.01. (IS THIS RIGHT? QUESTION)

Therefore, the chance that you actually have the disease, now that you test positive is:
\begin{equation*}
P(A|B) = \frac{0.99 * 0.0001}{0.01} = 0.0099
\end{equation*}

This is about 100X higher than baseline, but it is still >99% likely that you DO NOT have the disease.

#### 3b QUESTION
**Prove the conditionalized version of the general product rule:**
\begin{equation*}
P(A,B|E) = P(A|B, E)P(B|E)
\end{equation*}


**Prove the conditionalized version of Bayes’ rule:**
\begin{equation*}
P(A|B, E) = \frac{P(B|A, E)P(A|E)}{P(B|E)}
\end{equation*}

